{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling \n",
    "\n",
    "If you have the abstract, suppose you have a 100 papers, you can run topic modelling on the abstract in order to extract the topics in each paper. Then you do this sort of matching. You find a measure of similarity between what a user wants, in order to retrieve the matched papers. (This is called topic modeling: given a bunch of texts, extract its topics.)\n",
    "\n",
    "- Vintage approach: bag of words model. You can start with that. YOu embed the text thanks to the bag of words model. There are many tutorial that show you how to do that.  \n",
    "- Run PCA on the bag of words model! This is called DLA, not PCA. The goal of LDA (latent … allocation). In python this can be done in 3 lines of code. Simplest approach. \n",
    "- More advanced techniques: Hugging face is a python repository that contains thousands pretrained models. At the heart of large language models (we use them on a daily basis), there is a very peculiar deep learning architecture  which is called transformers. In short, transformers are are the standard for natural language generative models. You can go on hugging face. Hugging face > models > natural language processing (thousands of tasks) > sentence siimilarity/text classification/\n",
    "\n",
    "https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending \n",
    "\n",
    "Interesting article: \n",
    "- Leveraging BERTopic for the Analysis of Scientific Papers on Seaweed https://ieeexplore.ieee.org/document/10285737\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# You might need to change the path \n",
    "dionne_path = \"/Users/dionnespaltman/Desktop/Luiss /Data Science in Action/Project/openalex_papers.csv\"\n",
    "df = pd.read_csv(dionne_path)\n",
    "\n",
    "# my data is stored in a pandas dataframe for efficiency and ease of use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journ_ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>keywords</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W3034272367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ioannis Antonopoulos, Valentin Robu, Benoit Co...</td>\n",
       "      <td>Artificial intelligence and machine learning a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1016/j.rser.2020.109899</td>\n",
       "      <td>Recent years have seen an increasing interest ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020</td>\n",
       "      <td>Renewable and Sustainable Energy Reviews</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Smart Grid Energy Management', 'Energy Effic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W2141042444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W. Brian Arthur</td>\n",
       "      <td>The Economy as an Evolving Complex System II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1201/9780429496639</td>\n",
       "      <td>* Introduction W.B. Arthur, S.N., Durlauf, and...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2018</td>\n",
       "      <td>CRC Press eBooks</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Complex Systems and Time Series Analysis', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/W789578048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leonel A. Laboissiere, Ricardo A. S. Fernandes...</td>\n",
       "      <td>Maximum and minimum stock price forecasting of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1016/j.asoc.2015.06.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015</td>\n",
       "      <td>Applied Soft Computing</td>\n",
       "      <td>[{'id': 'https://openalex.org/keywords/stock',...</td>\n",
       "      <td>['Stock Market Forecasting Methods', 'Energy L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W4321748146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abhishek Aggarwal, Cheuk Chi Tam, Dezhi Wu, Xi...</td>\n",
       "      <td>Artificial Intelligence–Based Chatbots for Pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.2196/40789</td>\n",
       "      <td>Background Artificial intelligence (AI)–based ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2023</td>\n",
       "      <td>Journal of Medical Internet Research</td>\n",
       "      <td>[{'id': 'https://openalex.org/keywords/chatbot...</td>\n",
       "      <td>['Digital Mental Health Interventions', 'Mobil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/W2944828013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christina A. Roberto, Hannah G. Lawman, Michae...</td>\n",
       "      <td>Association of a Beverage Tax on Sugar-Sweeten...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1001/jama.2019.4249</td>\n",
       "      <td>Policy makers have implemented beverage taxes ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019</td>\n",
       "      <td>JAMA</td>\n",
       "      <td>[{'id': 'https://openalex.org/keywords/fluid-o...</td>\n",
       "      <td>['Obesity, Physical Activity, Diet', 'Nutritio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  submitter  \\\n",
       "0  https://openalex.org/W3034272367        NaN   \n",
       "1  https://openalex.org/W2141042444        NaN   \n",
       "2   https://openalex.org/W789578048        NaN   \n",
       "3  https://openalex.org/W4321748146        NaN   \n",
       "4  https://openalex.org/W2944828013        NaN   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Ioannis Antonopoulos, Valentin Robu, Benoit Co...   \n",
       "1                                    W. Brian Arthur   \n",
       "2  Leonel A. Laboissiere, Ricardo A. S. Fernandes...   \n",
       "3  Abhishek Aggarwal, Cheuk Chi Tam, Dezhi Wu, Xi...   \n",
       "4  Christina A. Roberto, Hannah G. Lawman, Michae...   \n",
       "\n",
       "                                               title  comments  journ_ref  \\\n",
       "0  Artificial intelligence and machine learning a...       NaN        NaN   \n",
       "1       The Economy as an Evolving Complex System II       NaN        NaN   \n",
       "2  Maximum and minimum stock price forecasting of...       NaN        NaN   \n",
       "3  Artificial Intelligence–Based Chatbots for Pro...       NaN        NaN   \n",
       "4  Association of a Beverage Tax on Sugar-Sweeten...       NaN        NaN   \n",
       "\n",
       "                                          doi  \\\n",
       "0  https://doi.org/10.1016/j.rser.2020.109899   \n",
       "1       https://doi.org/10.1201/9780429496639   \n",
       "2  https://doi.org/10.1016/j.asoc.2015.06.005   \n",
       "3               https://doi.org/10.2196/40789   \n",
       "4      https://doi.org/10.1001/jama.2019.4249   \n",
       "\n",
       "                                            abstract versions  year  \\\n",
       "0  Recent years have seen an increasing interest ...       []  2020   \n",
       "1  * Introduction W.B. Arthur, S.N., Durlauf, and...       []  2018   \n",
       "2                                                NaN       []  2015   \n",
       "3  Background Artificial intelligence (AI)–based ...       []  2023   \n",
       "4  Policy makers have implemented beverage taxes ...       []  2019   \n",
       "\n",
       "                                    journal  \\\n",
       "0  Renewable and Sustainable Energy Reviews   \n",
       "1                          CRC Press eBooks   \n",
       "2                    Applied Soft Computing   \n",
       "3      Journal of Medical Internet Research   \n",
       "4                                      JAMA   \n",
       "\n",
       "                                            keywords  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'id': 'https://openalex.org/keywords/stock',...   \n",
       "3  [{'id': 'https://openalex.org/keywords/chatbot...   \n",
       "4  [{'id': 'https://openalex.org/keywords/fluid-o...   \n",
       "\n",
       "                                              topics  \n",
       "0  ['Smart Grid Energy Management', 'Energy Effic...  \n",
       "1  ['Complex Systems and Time Series Analysis', '...  \n",
       "2  ['Stock Market Forecasting Methods', 'Energy L...  \n",
       "3  ['Digital Mental Health Interventions', 'Mobil...  \n",
       "4  ['Obesity, Physical Activity, Diet', 'Nutritio...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Recent years have seen an increasing interest ...\n",
       "1     * Introduction W.B. Arthur, S.N., Durlauf, and...\n",
       "2                                                   NaN\n",
       "3     Background Artificial intelligence (AI)–based ...\n",
       "4     Policy makers have implemented beverage taxes ...\n",
       "5     A well-functioning supply chain is a key to su...\n",
       "6     Web scraping or web crawling refers to the pro...\n",
       "7     In the era of digitalisation, e-commerce retai...\n",
       "8     Eye health and vision have widespread profound...\n",
       "9     The distribution company (DISCO) determines op...\n",
       "10    Abstract Artificial intelligence (AI) has the ...\n",
       "11    Ridehailing applications that collect mobility...\n",
       "12    The rapid advancement in artificial intelligen...\n",
       "13    Along with the development of smart grids, wid...\n",
       "14    Demand Response (DR) has gained popularity in ...\n",
       "15    Price promotions are used to influence purchas...\n",
       "16    Microalgae are a crucial part in many aquacult...\n",
       "17    Urea is an important raw material in the chemi...\n",
       "18    Algorithms permeate our lives in numerous ways...\n",
       "19    Purpose This paper is a literature review on u...\n",
       "20    In this paper, we propose a novel stock price ...\n",
       "21    Image-to-image translation is a class of visio...\n",
       "22    Energy storage systems are expected to play a ...\n",
       "23    Aquaculture and fisheries sectors are finding ...\n",
       "24    Conventional machine learning approaches aggre...\n",
       "Name: abstract, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the 'abstract' column as a Pandas Series\n",
    "abstracts = df['abstract']\n",
    "display(abstracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Recent years have seen an increasing interest in Demand Response (DR) as a means to provide flexibility, and hence improve the reliability of energy systems cost-effective way. Yet, high complexity tasks associated with DR, combined their use large-scale data frequent need for near real-time decisions, that Artificial Intelligence (AI) Machine Learning (ML) — branch AI recently emerged key technologies enabling demand-side response. methods can be used tackle various challenges, ranging from selecting optimal set consumers respond, learning attributes preferences, dynamic pricing, scheduling control devices, how incentivise participants DR schemes reward them fair economically efficient This work provides overview utilised applications, based on systematic review over 160 papers, 40 companies commercial initiatives, 21 projects. The papers are classified regards both AI/ML algorithm(s) application area DR. Next, initiatives presented (including start-ups established companies) innovation projects, where been paper concludes discussion advantages potential limitations reviewed techniques different tasks, outlines directions future research this fast-growing area.', '* Introduction W.B. Arthur, S.N., Durlauf, and D. Lane Asset Pricing Under Endogenous Expectations in an Artificial Stock Market J.H. Holland, B. LeBaron, R. Palmer, P. Tayler Natural Rationality V.M. Darley S.A. Kauffman Statistical Mechanics Approaches to Socioeconomic Behavior S.N. Durlauf Is What Good for Each Best All? Learning From Others the Information Contagion Model Evolution of Trading Structures Y.M. Ioannides Foresight, Complexity, Strategy Maxfield The Emergence Simple Ecologies Skill J.F. Padgett Some Fundamental Puzzles Economic History/Development D.C. North How Economy Organizes Itself Space: A Survey New Geography Krugman Time Money Shubik Promises J. Geanakoplos Macroeconomics Complexity: Inflation Theory A. Leijonhufvud Evolutionary Dynamics Game-Theoretic Models K. Lindgren Identification Anonymous Interactions C.F. Manski Price Complex Environments W.A. Brock Population Games L.E. Blume Computational Political Kollman, H. Miller, S. Page as Interactive System A.P. Kirman Economists Can Get Life L. Tesfatsion Thoughts About Distribution Economics P.W. Anderson', nan, 'Background Artificial intelligence (AI)–based chatbots can offer personalized, engaging, and on-demand health promotion interventions. Objective The aim of this systematic review was to evaluate the feasibility, efficacy, intervention characteristics AI for promoting behavior change. Methods A comprehensive search conducted in 7 bibliographic databases (PubMed, IEEE Xplore, ACM Digital Library, PsycINFO, Web Science, Embase, JMIR publications) empirical articles published from 1980 2022 that evaluated feasibility or efficacy screening, extraction, analysis identified were performed by following PRISMA (Preferred Reporting Items Systematic Reviews Meta-Analyses) guidelines. Results Of 15 included studies, several demonstrated high healthy lifestyles (n=6, 40%), smoking cessation (n=4, 27%), treatment medication adherence (n=2, 13%), reduction substance misuse (n=1, 7%). However, there mixed results regarding acceptability, usability. Selected change theories expert consultation used develop strategies chatbots, including goal setting, monitoring, real-time reinforcement feedback, support. Real-time user-chatbot interaction data, such as user preferences behavioral performance, collected on chatbot platform identify ways providing personalized services. potential scalability deployment through accessible devices platforms (eg, smartphones Facebook Messenger). participants also reported offered a nonjudgmental space communicating sensitive information. need be interpreted with caution because moderate risk internal validity, insufficient description techniques, limitation generalizability. Conclusions have interventions among large diverse populations; however, future studies adopt robust randomized control trials establish definitive conclusions.', \"Policy makers have implemented beverage taxes to generate revenue and reduce consumption of sweetened drinks. In January 2017, Philadelphia, Pennsylvania, became the second US city implement a excise tax (1.5 cents per ounce).To compare changes in prices sales following implementation Philadelphia compared with Baltimore, Maryland (a control without tax) assess potential cross-border shopping avoid neighboring zip codes.This study used difference-in-differences approach analyzed data between 1, 2016, before tax, December 31, after tax. Differences by store type, sweetener status, size were examined. The commercial retailer included large chain Pennsylvania codes bordering Philadelphia. These reflect approximately 25% ounces taxed beverages sold Philadelphia.Philadelphia's on sugar-sweetened artificially beverages.Change volume sales.A total 291 stores (54 supermarkets, 20 mass merchandise stores, 217 pharmacies) analyzed. mean price ounce increased from 5.43 2016 6.24 2017 at supermarkets; 5.28 6.60 8.28 pharmacies. Baltimore 5.33 5.50 6.34 6.52 6.76 6.93 per-ounce difference 2 cities was 0.65 (95% CI, 0.60 cents-0.69 cents; P<.001) 0.87 (95 % 0.72 cents-1.02 1.56 1.50 cents-1.62 Total decreased 1.3 billion (from 2.475 1.214 billion) or 51.0% implementation. Volume border codes, however, 308.2 million 713.1 1.021 billion), offsetting decrease Philadelphia's 24.4%. 4-week period periods 4.85 1.99 2.98 1.72 0.16 0.13 2.83 2.81 1.05 1.00 0.14 This 58.7% reduction supermarkets (difference-in-differences, -2.85 ounces; 95% -4.10 -1.60 P < .001), 40.4% -1.20 -2.04 -0.36 = 12.6% pharmacies -0.02 -0.03 -0.01 .001).In associated significantly higher significant substantial decline sold. partially offset increases areas.\", 'A well-functioning supply chain is a key to success for every business entity. Having an accurate projection on inventory offers substantial competitive advantage. There are many internal factors like product introductions, distribution network expansion; and external such as weather, extreme seasonality, changes in customer perception or media coverage that affects the performance of chain. In recent years Artificial Intelligence (AI) has been proved become extension our brain, expanding cognitive abilities levels we never thought would be possible. Though believe AI will replace humans, it not true, rather help us unleash true strategic creative potential. consists set computational technologies developed sense, learn, reason, act appropriately. With technological advancement mobile computing, capacity store huge data internet, cloud-based machine learning information processing algorithms etc. integrated into sectors reduce costs, increase revenue, enhance asset utilization. helping businesses get almost 100% forecast demand, optimizing their R&amp;D manufacturing with lower cost higher quality, them promotion (identifying target customers, demography, defining price, designing right message, etc.) providing customers better experience. These four areas value creation extremely important gaining Supply-chain leaders use AI-powered a) make efficient designs eliminate waste b) real-time monitoring error-free production c) facilitate process cycle times. processes crucial bringing Innovation faster market.', 'Web scraping or web crawling refers to the procedure of automatic extraction data from websites using software. It is a process that particularly important in fields such as Business Intelligence modern age. scrapping technology allow us extract structured text HTML. extremely useful situations where isn’t provided machine readable format JSON XML. The use gather allows prices near real time retail store sites and provide further details, can also be used intelligence illicit businesses drug marketplaces darknet law enforcement researchers valuable varieties would unavailable with conventional methods. has been found program yield far more thorough, accurate, consistent than manual entry. Based on result it concluded highly tool information age, an essential one fields. Multiple technologies are required implement properly spidering pattern matching which discussed. This paper looking into what is, how works, stages, technologies, relates Intelligence, artificial intelligence, science, big data, cyber securityو done Python language, some main benefits scraping, future may look like, special degree emphasis placed highlighting ethical legal issues. Keywords: Scraping, Crawling, Language, Data Science, Artificial Big Data, Cloud Computing, Cybersecurity, legal, ethical.', \"In the era of digitalisation, e-commerce retail sites have become decisive channels for reaching millions potential customers worldwide. Digital marketing strategies are formulated by teams in order to increase traffic on their sites, thereby boosting sales products. With massive amount data available from cloud, which were conventionally made with a high degree intuition based decision makers' knowledge and experience, can now be supported application artificial intelligence techniques. This paper introduces novel approach applying fuzzy association rule mining logic technique, discovering factors influencing pricing products launched site, formulating flexible, dynamic each product an site. A support system B2B businesses, namely Smart-Quo, is developed implemented Hong Kong-based company. six-month pilot run reveals significant improvement terms efficiency effectiveness making decisions product. The case study demonstrates feasibility benefits techniques management today's digital age.\", \"Eye health and vision have widespread profound implications for many aspects of life, health, sustainable development, the economy. Yet nowadays, people, families, populations continue to suffer consequences poor access high-quality, affordable eye care, leading impairment blindness. In 2020, an estimated 596 million people had distance worldwide, whom 43 were blind. Another 510 uncorrected near impairment, simply because not having reading spectacles. A large proportion those affected (90%), live in low-income middle-income countries (LMICs). However, encouragingly, more than 90% with a preventable or treatable cause existing highly cost-effective interventions. conditions affect all stages young children older being particularly affected. Crucially, women, rural populations, ethnic minority groups are likely this pervasive inequality needs be addressed. By 2050, population ageing, growth, urbanisation might lead 895 61 will Action prioritise is needed now. This Commission defines as maximised vision, ocular functional ability, thereby contributing overall wellbeing, social inclusion, quality life. essential achieve Sustainable Development Goals (SDGs). Poor impaired negative effect on life restrict equitable achievement education workplace. Vision loss has substantial financial individuals, communities. Although high-quality data global economic estimates scarce, LMICs, conservative assessments based latest prevalence figures 2020 suggest that annual productivity from approximately US$410·7 billion purchasing power parity. reduces mobility, affects mental exacerbates risk dementia, increases likelihood falls road traffic crashes, need ultimately leads higher mortality rates. contrast, facilitates daily activities, enables better educational outcomes, work productivity, reducing inequality. An increasing amount evidence shows potential advance SDGs, by towards poverty reduction, zero hunger, good education, gender equality, decent work. public priority, transforming lives both wealthy Therefore, reframed development well issue given greater prominence within agendas. causes require promotional, preventive, treatment, rehabilitative Cataract, refractive error, glaucoma, age-related macular degeneration, diabetic retinopathy responsible most impairment. Research identified treatments reduce eliminate blindness these conditions; priority deliver where they needed. Proven care interventions, such cataract surgery spectacle provision, among care. Greater investment so millions living unnecessary can benefit Lessons past three decades give hope challenge met. Between 1990 age-standardised fell 28·5%. Since 1990s, major infectious blindness—onchocerciasis trachoma—have declined substantially. Hope remains 2030, transmission onchocerciasis interrupted, trachoma eliminated problem every country worldwide. ageing led crude blindness, thus increased total number some regions. Key messagesEye Goals; issueThere extensive showing improving contributes directly indirectly achieving Goals, including general equity. Improving practical way unlocking human potential. enabling, cross-cutting framework.Almost everyone experience condition during their lifetime services; urgent action necessary meet rapidly growing needIn 1·1 presbyopia. figure expected rise 1·8 billion. Most (LMICs) avoidable During course, even if just glasses. Because unmet population, concern which warrants political action.Eye component universal coverage; it must included planning, resourcing, delivery careUniversal coverage without affordable, high quality, line WHO World report we urge consider service coverage. To comprehensive services promotion, prevention, rehabilitation, national strategic plans policies, financing structures, workforce planning. Coordinated intersectoral systematically improve also healthy initiatives, schools, Integration multiple relevant components at levels system central importance.High universally delivered; concerted providing effective, efficient, safe, timely, equitable, people-centred careUse effective indicators error highlight gap between outcomes. We providers take holistic view emphasise design individual needs: approach. Services characterised inclusiveness equity delivery, proactively addressing marginalised vulnerable through targeted encourage improved surgery, support redefining outcome threshold 6/12 better.Highly vision-restoring interventions offer enormous outlook individuals nations; scale up requiredFor estimate resulted $410·7 lost productivity; full cost higher. Treatments would cost-effective. The case invest compelling resources urgently required.Financial barriers accessing leave behind; pool riskHealth-care costs prevent services. integrated into remove barriers. whole mitigate expenditure, mechanisms desirable.Technology treatment developments new tools health; thoughtful application maximise coverage, accessibility, efficiency, affordabilityTechnological telemedicine, mHealth, artificial intelligence revolutionise next decade delivering remote areas. caution ensure developments.The unable countries; expansion capacity required numbers, sharing tasks, strengthened training, enabling environments, leadershipMany areas shortages personnel working health. available distributed according need. Quality training updated, renewed emphasis competency. Enabling environments created, appropriate support, supervision, equipment. Long-standing issues low resolved. Mentoring other programmes cultivate emerging generation leaders needed.Reliable survey key progress robust indicator shape change drive actionTo monitor balanced set needed, outlined Commission. Service should used implementers policy makers change. scarcity epidemiological several regions, addressed priority.Research been crucial advances understanding treating disease; solution-focused, contextually research innovative prevention strategies inform implementation coverageImplementation guide Discovery specific remain efficacious impact benefits only partly understood; coordinated effort collect step-change LMICs do commitment diversity inclusion community. There framework. Almost action. Universal importance. High Use better. Highly For required. Financial Health-care desirable. Technology affordability Technological developments. leadership Many Reliable priority. Implementation Despite progress, business usual keep pace demographic trends address inequities persist each country. New threats emerging, worldwide increase retinopathy, myopia, prematurity, chronic diseases glaucoma degeneration. With projected associated over coming decades, develop previously achieved. Good community level luxury urban brought mainstream policy, financing, (promotion, rehabilitation) range context Accessing bring falling envisaged framework health-care quality: people-centred, integrated, efficient. add environmentally sustainable. Multiple obstacles overcome Important include complex availability services, cost, maldistribution well-trained personnel, lack suitable, maintained equipment consumables. These but occur underserved communities high-income countries. Strong partnerships formed natural allies non-communicable diseases, neglected tropical children's disability, rehabilitation. sector traditionally focused underused promotion lessen disease Solving problems depend solutions established scale. Evidence-based approaches deficiencies supply demand. Strategic investments discovery research, harnessing findings diverse fields, globally. Encouragingly, mobile intelligence, learning could potentially enable professionals plentiful, did Grand Challenges Global Health prioritisation exercise broad challenges spanning fields epidemiology, systems, diagnostics, therapeutics, implementation. issues, picked 3400 suggestions proposed 336 118 countries, help frame future agenda Commission, harness lessons learned two present life-transforming provide thorough rapid field. was created consultation involving experts outside governments stakeholders about path forward beyond further SDGs (including coverage), world loss. few years time its partners government, sectors successes encountered same chart upcoming decades. Moving requires building strong foundation laid VISION impetus all.\", 'The distribution company (DISCO) determines optimal retail prices to operate the network efficiently while promoting demand response (DR) programs. In addition, an energy storage system (ESS), which improves peak load management, is widely used for price-based DR. This paper proposes electricity pricing strategy that considers operation of ESS using a machine learning algorithm. An artificial neural (ANN) develop practical model DR scheduling ESS. trained historical data include price and corresponding obtained from building management system. proposed replicated mathematical equations directly integrated into constraints optimization problem ANN-based allows development with single-level structure reflecting decision-making process both DISCO operator. verified through case studies, prove successfully expresses price-optimal function has high applicability. results demonstrate can accurately determine balancing points reducing load.', \"Abstract Artificial intelligence (AI) has the ability to enhance insurance industry's value chain by altering relationships, reinventing business platforms, and expanding hidden data. Insurance companies will apply AI greatly large data analytics, evolve algorithms with transactional faster, combine in new ways discover better underwriting risks appropriately price risk of various insureds based on true their risks. This article explores how have a significant impact workforce, jobs, furthermore elimination jobs potentially exacerbate social equality gaps global scale, leading shift culture increased inflation, thus impacting industry as well its customers.\", \"Ridehailing applications that collect mobility data from individuals to inform smart city planning predict each trip's fare pricing with automated algorithms rely on artificial intelligence (AI). This type of AI algorithm, namely a price discrimination is widely used in the industry's black box systems for dynamic individualized pricing. Lacking transparency, studying such fairness and disparate impact has not been possible without access generating outcomes algorithms. Recently, an effort enhance transparency planning, Chicago regulation mandated transportation providers publish anonymized ridehailing. As result, we present first large-scale measurement by ridehailing applications.\", \"The rapid advancement in artificial intelligence and machine learning techniques, availability of large-scale data, increased computational capabilities the opens door to develop sophisticated methods predicting stock price. In meantime, easy access investment opportunities has made market more complex volatile than ever. world is looking for an accurate reliable predictive model which can capture market's highly nonlinear behavior a holistic framework. This study uses long short-term memory (LSTM), particular neural network architecture, predict next-day closing price S&P 500 index. A well-balanced combination nine predictors carefully constructed under umbrella fundamental macroeconomic technical indicators broader sense. Single layer multilayer LSTM models are developed using chosen input variables, their performances compared standard assessment metrics–Root Mean Square Error (RMSE), Absolute Percentage (MAPE), Correlation Coefficient (R). experimental results show that single provides superior fit high prediction accuracy models.\", 'Along with the development of smart grids, wide adoption electric vehicles (EVs) is seen as a catalyst to reduction CO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> emissions and more intelligent transportation systems. In particular, EVs augment grid ability store energy at some points in network give it back others and, therefore, help optimize use from intermittent renewable sources let users refill their cars variety locations. However, number challenges need be addressed if such benefits are achieved. On one hand, given limited range costs involved charging EV batteries, important design algorithms that will minimize same time, avoid being stranded. other collectives organized way peaks on may result high electricity prices overload local distribution grids. order meet challenges, technological solutions have been proposed. this paper, we focus those utilize artificial intelligence techniques render systems manage smarter. provide survey literature identify commonalities key differences approaches. This allows us develop classification benchmarks can used advance state art space.', 'Demand Response (DR) has gained popularity in recent years as a practical strategy to increase the sustainability of energy systems while reducing associated costs. Despite this, Artificial Intelligence (AI) and Machine Learning (ML), have recently developed critical technologies for demand-side management response due high complexity tasks with DR, well huge amount data take decisions very near real time implications. Selecting best group users respond, learning their attitude toward consumptions priorities, price optimization, monitoring control devices, engage more consumers DR schemes, how remunerate them fairly economically are all problems that can be tackled help AI techniques. This study presents an overview approaches used applications. Both algorithm(s) employed discussing commercial efforts (from both new existing businesses) large-scale innovation projects applied DR. Different kind programs implemented different countries also discussed. Moreover, it discusses application blockchain schemes smart grid paradigm. Discussion strengths weaknesses evaluated methods various tasks, suggestions further study, round out work.', 'Price promotions are used to influence purchases and represent an important target for obesity prevention policy. However, no long-term contemporary data on the extent frequency of supermarket price exists. We aimed evaluate frequency, magnitude weekly variation beverage available online at two major Australian chains over 50 weeks.Beverages were categorised into four policy-relevant categories (sugar-sweetened beverages, artificially-sweetened flavoured milk 100% juice, water). The proportional contribution each category total number proportions, proportion within product category, mean discount, in calculated.For Coles Woolworths respectively, 26% 30% all beverages promoted any given week. Sugar-sweetened made up greatest (Coles: 46%, Woolworths: 49%). Within sugar-sweetened that was similar, higher than other reasonably constant time. Diet drinks soft most heavily discounted (by 29-40%).Beverage extensively supermarkets, undermining efforts promote healthy population diets. Implications public health: Policies restricting likely be part strategies reduce improve nutrition.', 'Microalgae are a crucial part in many aquaculture feed applications processes, mainly hatcheries. Many hatcheries maintain small scale microalgae production facility in-house for the of live feed. usually grown non-automated bubble-column systems at unknown costs. Other reactor or scenarios utilizing artificial light sunlight and different scales could result more cost efficient processes. To determine cost-price cost-distribution facilities Dutch industry identify most reducing strategies techno-economic analysis (25-1500 m2) was developed. Commercially available reactors commonly used were compared; tubular photobioreactors (TPBR) bubble-columns (BC) two placement possibilities; using an indoor (AL) greenhouse (GH) under climate conditions. Data from commercial Netherlands to model reference describing price with state art technology biomass capacity 125 kg year−1. The algae (on basis dry matter) is calculated €290,- kg−1 € 329 greenhouse, respectively €587,- €573 respectively. addition will significantly reduce costs (by 33%) all small-scale modelled. Biomass yield on (Yx,ph) showed largest effect when not considering process. Process parameters like temperature control should be aimed optimizing Yx,ph rather than other forms reduction. has very large impact price. With technologies reduction 92% achieved by changing 25m2 1500m2, resulting €43,- kg−1, producing 3992 year−1 greenhouse. presented gives valuable insights distribution aquaculture. This allows focus research efforts towards promising methods optimize existing companies achieve economically sustainable', 'Urea is an important raw material in the chemical industry and widely used as a nitrogen source fertilizers. The current industrial urea synthesis not only requires harsh reaction conditions, but also consumes most of NH3 obtained through artificial synthesis. conversion N2 CO2 into electrochemical reactions under ambient conditions represents novel green method. However, large-scale promotion this method limited by lack suitable electrocatalysts. Here, means density functional theory computations, we systematically study catalytic activity three experimentally available two-dimensional metal borides (MBenes), Mo2B2, Ti2B2, Cr2B2 toward simultaneous electrocatalytic coupling to produce conditions. According our results, these MBenes have superior intrinsic basal for formation, with limiting potentials ranging from -0.49 -0.65 eV, can significantly suppress competitive reduction NH3. In particular, 2D Mo2B2 possess capacity surface oxidation self-corrosion rendering them relatively promising electrocatalysts production. Our work paves way urea.', 'Algorithms permeate our lives in numerous ways, performing tasks that until recently could only be carried out by humans. Artificial Intelligence (AI) technologies, based on machine learning algorithms and big-data-powered systems, can perform sophisticated such as driving cars, analyzing medical data, evaluating executing complex financial transactions - often without active human control or supervision. also play an important role determining retail pricing, online advertising, loan qualification, airport security. In this work, Martin Ebers Susana Navas bring together a group of scholars practitioners from across Europe the US to analyze how shift actors computers presents both practical conceptual challenges for legal regulatory systems. This book should read anyone interested intersection between computer science law, law better regulate algorithmic design, ramifications citizens whose behavior is increasingly dictated algorithms.', 'Purpose This paper is a literature review on use of artificial intelligence (AI) among agricultural value chain (AVC) actors, and it brings out gaps in research this area provides directions for future research. Design/methodology/approach The authors systematically collected from several databases covering 25 years (1994–2020). They classified based AVC actors present different stages AVC. was analysed using Nvivo 12 (qualitative software) descriptive content analysis. Findings Fifty percent the reviewed studies were empirical, 35% conceptual. showed that AI adoption could increase agriculture income, enhance competitiveness reduce cost. Among stages, related to processing consumer sector very low compared input, production quality testing. Most widely used deep learning algorithm neural networks various aspects such as water resource management, yield prediction, price/demand forecasting, energy efficiency, optimalization fertilizer/pesticide usage, crop planning, personalized advisement predicting behaviour. Research limitations/implications have considered only AVC, any other not included study. Originality/value Earlier focussed specific areas inputs, farming, processing, distribution so on. There no entire AI. has filled gap.', 'In this paper, we propose a novel stock price prediction model based on deep learning. With the success of learning algorithms in field Artificial Neural Network (ANN), choose to solve regression problems (stock our case). Stock is challenging problem due its random movement. This hybrid combination two well-known networks, Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU). We S&P 500 historical time series data use significant evaluation metrics such as mean squared error, absolute percentage error etc., that conventional approaches have used. experiment section, described effectiveness each component along with performance gain over state-of-the-art approach. Our provides less by considering nature (change) for large scale data.', 'Image-to-image translation is a class of vision and graphics problems where the goal to learn mapping between an input image output using training set aligned pairs. However, for many tasks, paired data will not be available. We present approach learning translate from source domain X target Y in absence examples. Our G : → such that distribution images G(X) indistinguishable adversarial loss. Because this highly under-constrained, we couple it with inverse F introduce cycle consistency loss push F(G(X)) ≈ (and vice versa). Qualitative results are presented on several tasks does exist, including collection style transfer, object transfiguration, season photo enhancement, etc. Quantitative comparisons against prior methods demonstrate superiority our approach.', 'Energy storage systems are expected to play a fundamental part in the integration of increasing renewable energy sources into electric system. They already used power plants for different purposes, such as absorbing effect intermittent or providing ancillary services. For this reason, it is imperative research managing and sizing methods that make with viable profitable projects. In paper, method presented, where particle swarm optimisation reach maximum profits. This compared expert systems, proving former achieves better results, while respecting similar rules. The paper further presents which uses previous one plant possible. Finally, both tested through simulations show their potential.', 'Aquaculture and fisheries sectors are finding ingenious ways to grow meet the soaring human demand for nutrient-rich fish seafood by efficiently utilizing vast water resources biodiversity of aquatic life on earth. This includes progressive integration information technology, data science artificial intelligence with fishing farming methods enable intensification aquaculture production, sustainable exploitation natural fishery mechanization-automation allied activities. Exclusive mining machine learning systems being developed process complex datasets perform intelligent tasks like analysing cause-effect associations, forecasting problems providing smart-precision solutions catching fish. Considering intensifying research growing interest stakeholders, in this review, we have consolidated basic various practical applications domains from representative selection scientific literature. an overview (1) activities such as monitoring control production environment, optimization feed use, biomass disease prevention; (2) management aspects resource assessment, fishing, catch regulation; (3) environment related hydrology, primary pollution; (4) automation processing quality assurance systems; (5) market intelligence, price socioeconomics. While has been relatively faster integrating tools advanced systems, capture is reliable sort complexities collection processing. Finally, pointed out some challenges future perspectives large-scale adoption.', 'Conventional machine learning approaches aggregate all training data in a central server, which causes massive communication overhead of transmission and is also vulnerable to privacy leakage. Thereby, blockchain-based federated has emerged protect Artificial Intelligence Things (AIoT) devices from exposing their private by the Federated Learning (FL) framework, enables decentralized model without vulnerability server. However, existing FL systems still suffer (i) limited scalability single blockchain framework; (ii) large costs incurred iterative large-size update transmission. To this end, we first design an efficient cross-chain framework for scalable flexible management, multiple blockchains are customized specific tasks individually perform protection. A scheme proposed enable secure collaboration interactions training, trading, payment. We then propose compression save almost compromising accuracy. Moreover, trading markets, dynamic pricing using learning-based auction trading. Numerical results demonstrate that schemes achieve scalable, flexible, communication-efficient AIoT.']\n"
     ]
    }
   ],
   "source": [
    "abstracts_list = df['abstract'].tolist()\n",
    "print(abstracts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic wikipedia\n",
    "Wikipedia BERTopic:  https://huggingface.co/MaartenGr/BERTopic_Wikipedia\n",
    "\n",
    "? Unclear what format the data should be in \n",
    "? Also a relatively small model, so perhaps it's better to use another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you've installed these in your terminal before running the code\n",
    "pip install -U bertopic\n",
    "pip install -U safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the documentation it was used as follows \n",
    "\n",
    "# from bertopic import BERTopic\n",
    "# topic_model = BERTopic.load(\"MaartenGr/BERTopic_Wikipedia\")\n",
    "\n",
    "# topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load(df)\n",
    "topic_model.get_topic_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT base uncased\n",
    "https://huggingface.co/google-bert/bert-base-uncased\n",
    "\n",
    "? Unclear what format the data should be in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(abstracts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m TFBertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReplace me by any text you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md like.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstracts_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m output \u001b[38;5;241m=\u001b[39m model(encoded_input)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2877\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2875\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2876\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2877\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2879\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2965\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2961\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2962\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2963\u001b[0m         )\n\u001b[1;32m   2964\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2988\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2989\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3007\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3008\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3167\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3158\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3159\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3160\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3164\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3165\u001b[0m )\n\u001b[0;32m-> 3167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3169\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3185\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/tokenization_utils.py:888\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 888\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    890\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/tokenization_utils.py:868\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 868\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    870\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
     ]
    }
   ],
   "source": [
    "# ValueError: Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(abstracts_list, return_tensors='tf')\n",
    "output = model(encoded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example text input\n",
    "text = \"Hello, how are you?\"\n",
    "\n",
    "# Tokenize the input (adding special tokens and converting to tensors)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# The encoded_input is a dictionary that might look like:\n",
    "# {\n",
    "#   'input_ids': tensor([[101, 7592, 1010, 2129, 2024, 2017, 102]]),\n",
    "#   'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])\n",
    "# }\n",
    "# If you're doing a sentence pair, token_type_ids will also be included.\n",
    "\n",
    "# Feed the encoded input to the model\n",
    "output = model(**encoded_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
