{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling \n",
    "\n",
    "If you have the abstract, suppose you have a 100 papers, you can run topic modelling on the abstract in order to extract the topics in each paper. Then you do this sort of matching. You find a measure of similarity between what a user wants, in order to retrieve the matched papers. (This is called topic modeling: given a bunch of texts, extract its topics.)\n",
    "\n",
    "- Vintage approach: bag of words model. You can start with that. YOu embed the text thanks to the bag of words model. There are many tutorial that show you how to do that.  \n",
    "- Run PCA on the bag of words model! This is called DLA, not PCA. The goal of LDA (latent â€¦ allocation). In python this can be done in 3 lines of code. Simplest approach. \n",
    "- More advanced techniques: Hugging face is a python repository that contains thousands pretrained models. At the heart of large language models (we use them on a daily basis), there is a very peculiar deep learning architecture  which is called transformers. In short, transformers are are the standard for natural language generative models. You can go on hugging face. Hugging face > models > natural language processing (thousands of tasks) > sentence siimilarity/text classification/\n",
    "\n",
    "https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending \n",
    "\n",
    "Interesting article: \n",
    "- Leveraging BERTopic for the Analysis of Scientific Papers on Seaweed https://ieeexplore.ieee.org/document/10285737\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# You might need to change the path \n",
    "dionne_path = \"/Users/dionnespaltman/Desktop/Luiss /Data Science in Action/Project/openalex_papers.csv\"\n",
    "df = pd.read_csv(dionne_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
